{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "` Deliverable URLs of the colab notebook: `\n",
    "\n",
    "\n",
    "https://colab.research.google.com/drive/17wYGMvMr0YnFYWwdgaMfHbsSsFWJjYGf?usp=sharing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas scikit-learn nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\TANISHQ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\TANISHQ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing stop works and usernames\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem import *\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Hate Detection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hate = pd.read_csv('data/hate/train.csv')\n",
    "val_hate = pd.read_csv('data/hate/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3660, 2), (457, 2))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hate.shape, val_hate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(pd.DataFrame(train_hate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove arabic words\n",
    "dot(.) is used instead of space\n",
    "can just remove punctuations\n",
    "Remove twitter or any types of links (yt links also present)\n",
    "lowercase everything\n",
    "remove @usernames\n",
    "remove numbers\n",
    "same words used in many contexts both hate and non hate like rape, murder\n",
    "hate word is used in many hate sentences\n",
    "words that are pronuns instead of nouns are more directed to sarcasm. Like TU, tera rather than someones name - just random assumption not correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of words</th>\n",
       "      <th>Training Set</th>\n",
       "      <th>Validation Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hate Words</td>\n",
       "      <td>1353</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Hate Words</td>\n",
       "      <td>2307</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Number of words  Training Set  Validation Set\n",
       "0      Hate Words          1353             148\n",
       "1  Not Hate Words          2307             309"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hateCount_train = len(train_hate[train_hate['Tag'] == 1])\n",
    "nothateCount_train = len(train_hate[train_hate['Tag'] == 0])\n",
    "hateCount_val = len(val_hate[val_hate['Tag'] == 1])\n",
    "nothateCount_val = len(val_hate[val_hate['Tag'] == 0])\n",
    "\n",
    "word_count_df = pd.DataFrame(\n",
    "         {\n",
    "        'Number of words': [\"Hate Words\", \"Not Hate Words\"],\n",
    "        'Training Set': [hateCount_train, nothateCount_train],\n",
    "        'Validation Set': [hateCount_val, nothateCount_val]\n",
    "        },\n",
    "    )\n",
    "word_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "\n",
    "# Fit and transform the text data\n",
    "X_train = vectorizer.fit_transform(train_hate[\"Sentence\"])\n",
    "# Convert sparse matrix to array for better readability\n",
    "# X_array = X.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TextClassifier:\n",
    "    def __init__(self, model_type=\"svm_linear\"):\n",
    "        \"\"\"\n",
    "        Initialize the classifier.\n",
    "\n",
    "        model_type: \n",
    "            \"svm_linear\" -> Linear SVM (fast for high-dim features)\n",
    "            \"svm_rbf\"    -> RBF SVM (slow for large data)\n",
    "            \"naive_bayes\" -> Multinomial NaÃ¯ve Bayes (best for text)\n",
    "            \"logistic_regression\" -> Logistic Regression\n",
    "        \"\"\"\n",
    "        self.model_type = model_type\n",
    "        self.model = self._initialize_model(model_type)\n",
    "\n",
    "    def _initialize_model(self, model_type):\n",
    "        \"\"\"Initialize the selected model.\"\"\"\n",
    "        if model_type == \"svm_linear\":\n",
    "            return SVC(kernel=\"linear\",verbose=True, gamma='auto')\n",
    "        elif model_type == \"svm_rbf\":\n",
    "            return SVC(kernel=\"rbf\",  verbose=True)\n",
    "        elif model_type == \"naive_bayes\":\n",
    "            return MultinomialNB()\n",
    "        elif model_type == \"logistic_regression\":\n",
    "            return LogisticRegression(class_weight='balanced')\n",
    "        elif model_type == \"random_forest\":\n",
    "            return RandomForestClassifier(class_weight='balanced')\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model_type. Choose from 'svm_linear', 'svm_rbf', 'naive_bayes', 'logistic_regression'.\")\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"Train the model.\"\"\"\n",
    "        print(f\"Training {self.model_type} model...\")\n",
    "        self.model.fit(X_train, y_train)\n",
    "        print(\"Training completed.\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predict labels for new data.\"\"\"\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"Evaluate the model using accuracy, precision, recall, and F1-score.\"\"\"\n",
    "        y_pred = self.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        print(f\"\\nðŸ”¹ Model: {self.model_type}\")\n",
    "        print(f\"âœ… Accuracy: {accuracy:.4f}\")\n",
    "        print(report)\n",
    "        print(matrix)\n",
    "        \n",
    "    def predict_proba(self, X_test):\n",
    "        \"\"\"Predict probabilities for each class.\"\"\"\n",
    "        return self.model.predict_proba(X_test)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SVM Linear Classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training svm_linear model...\n",
      "[LibSVM]Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize with SVM (linear)\n",
    "classifier = TextClassifier(model_type=\"svm_linear\")\n",
    "\n",
    "# Train on dataset\n",
    "classifier.fit(X_train, train_hate['Tag'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Model: svm_linear\n",
      "âœ… Accuracy: 0.7002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.79       309\n",
      "           1       0.56      0.37      0.45       148\n",
      "\n",
      "    accuracy                           0.70       457\n",
      "   macro avg       0.65      0.61      0.62       457\n",
      "weighted avg       0.68      0.70      0.68       457\n",
      "\n",
      "[[265  44]\n",
      " [ 93  55]]\n"
     ]
    }
   ],
   "source": [
    "X_test = vectorizer.transform(val_hate[\"Sentence\"])\n",
    "y_test = val_hate['Tag']\n",
    "\n",
    "# Evaluate on test data\n",
    "classifier.evaluate(X_test, y_test)\n",
    "# y_pred = sgd_svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `RBF Kernel SVM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training svm_rbf model...\n",
      "[LibSVM]Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize with SVM (linear)\n",
    "classifier = TextClassifier(model_type=\"svm_rbf\")\n",
    "\n",
    "# Train on dataset\n",
    "classifier.fit(X_train, train_hate['Tag'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Model: svm_rbf\n",
      "âœ… Accuracy: 0.7002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.82       309\n",
      "           1       0.76      0.11      0.19       148\n",
      "\n",
      "    accuracy                           0.70       457\n",
      "   macro avg       0.73      0.55      0.50       457\n",
      "weighted avg       0.72      0.70      0.61       457\n",
      "\n",
      "[[304   5]\n",
      " [132  16]]\n"
     ]
    }
   ],
   "source": [
    "X_test = vectorizer.transform(val_hate[\"Sentence\"])\n",
    "y_test = val_hate['Tag']\n",
    "\n",
    "# Evaluate on test data\n",
    "classifier.evaluate(X_test, y_test)\n",
    "# y_pred = sgd_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Naive Bayes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training naive_bayes model...\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize with SVM (linear)\n",
    "classifier = TextClassifier(model_type=\"naive_bayes\")\n",
    "\n",
    "# Train on dataset\n",
    "classifier.fit(X_train, train_hate['Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Model: naive_bayes\n",
      "âœ… Accuracy: 0.7177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.95      0.82       309\n",
      "           1       0.69      0.24      0.35       148\n",
      "\n",
      "    accuracy                           0.72       457\n",
      "   macro avg       0.70      0.59      0.59       457\n",
      "weighted avg       0.71      0.72      0.67       457\n",
      "\n",
      "[[293  16]\n",
      " [113  35]]\n"
     ]
    }
   ],
   "source": [
    "X_test = vectorizer.transform(val_hate[\"Sentence\"])\n",
    "y_test = val_hate['Tag']\n",
    "\n",
    "# Evaluate on test data\n",
    "classifier.evaluate(X_test.toarray(), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Logistic Regression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training logistic_regression model...\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize with SVM (linear)\n",
    "classifier = TextClassifier(model_type=\"logistic_regression\")\n",
    "\n",
    "# Train on dataset\n",
    "classifier.fit(X_train, train_hate['Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Model: logistic_regression\n",
      "âœ… Accuracy: 0.6805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.78       309\n",
      "           1       0.51      0.36      0.42       148\n",
      "\n",
      "    accuracy                           0.68       457\n",
      "   macro avg       0.62      0.60      0.60       457\n",
      "weighted avg       0.66      0.68      0.66       457\n",
      "\n",
      "[[258  51]\n",
      " [ 95  53]]\n"
     ]
    }
   ],
   "source": [
    "X_test = vectorizer.transform(val_hate[\"Sentence\"])\n",
    "y_test = val_hate['Tag']\n",
    "\n",
    "# Evaluate on test data\n",
    "classifier.evaluate(X_test.toarray(), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Random Forest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training random_forest model...\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize with SVM (linear)\n",
    "classifier = TextClassifier(model_type=\"random_forest\")\n",
    "\n",
    "# Train on dataset\n",
    "classifier.fit(X_train, train_hate['Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Model: random_forest\n",
      "âœ… Accuracy: 0.7046\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82       309\n",
      "           1       0.70      0.16      0.25       148\n",
      "\n",
      "    accuracy                           0.70       457\n",
      "   macro avg       0.70      0.56      0.53       457\n",
      "weighted avg       0.70      0.70      0.63       457\n",
      "\n",
      "[[299  10]\n",
      " [125  23]]\n"
     ]
    }
   ],
   "source": [
    "X_test = vectorizer.transform(val_hate[\"Sentence\"])\n",
    "y_test = val_hate['Tag']\n",
    "\n",
    "# Evaluate on test data\n",
    "classifier.evaluate(X_test.toarray(), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom stopwords from a text file\n",
    "def load_stopwords(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        stopwords = set(file.read().splitlines())  # Read line by line into a set\n",
    "    return stopwords\n",
    "\n",
    "# Example usage\n",
    "custom_stopwords = load_stopwords(\"stop_hinglish.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Preprocessing words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # # # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "   \n",
    "    # removing usernames from text would lead to loss of info as hate is directed after mentions \n",
    "    # text = re.sub(r\"@[A-Za-z0-9]+\", \"\", text)\n",
    "\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # # Remove stopwords\n",
    "    # stop_words = set(stopwords.words('english'))\n",
    "    # text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runinng the model with preprocessed text\n",
    "X_train = train_hate['Sentence'].apply(preprocess_text)\n",
    "X_val = val_hate['Sentence'].apply(preprocess_text)\n",
    "\n",
    "# train_hate['Sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "# Fit and transform the text data\n",
    "X_train = vectorizer.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training naive_bayes model...\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "classifier = TextClassifier(model_type=\"naive_bayes\")\n",
    "\n",
    "# Train on dataset\n",
    "classifier.fit(X_train, train_hate['Tag'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = vectorizer.transform(val_hate[\"Sentence\"])\n",
    "\n",
    "y_test = val_hate['Tag']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Model: naive_bayes\n",
      "âœ… Accuracy: 0.7155\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.95      0.82       309\n",
      "           1       0.68      0.23      0.34       148\n",
      "\n",
      "    accuracy                           0.72       457\n",
      "   macro avg       0.70      0.59      0.58       457\n",
      "weighted avg       0.71      0.72      0.66       457\n",
      "\n",
      "[[293  16]\n",
      " [114  34]]\n"
     ]
    }
   ],
   "source": [
    "classifier.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Humour Classification`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_humor = pd.read_csv('data/humor/train.csv')\n",
    "val_humor = pd.read_csv('data/humor/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jyotiraditya Scindia is like \"Rassi jal gayee ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ishant Sharma ko bahut late utaara.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.@twinitisha neeche plug nikla hua hai..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaj agar India final me hota to kam se kam New...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 stages of life of Mechanical Engineer:\\n\\n1)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>Nitish &amp; Lalu scared of Modi so much that agar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>.@ShirishKunder Sabzi bana ke rakhna nahi to F...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>\"BARKHA se bacha lu tujhe seene se laga lu, aa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>\"Bol raha hai mere saath debate karega.. Muh k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>Pakistan ko har world cup ke baad captain bada...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2360 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Tag\n",
       "0     Jyotiraditya Scindia is like \"Rassi jal gayee ...    1\n",
       "1                   Ishant Sharma ko bahut late utaara.    1\n",
       "2              .@twinitisha neeche plug nikla hua hai..    0\n",
       "3     Aaj agar India final me hota to kam se kam New...    0\n",
       "4     3 stages of life of Mechanical Engineer:\\n\\n1)...    1\n",
       "...                                                 ...  ...\n",
       "2355  Nitish & Lalu scared of Modi so much that agar...    1\n",
       "2356  .@ShirishKunder Sabzi bana ke rakhna nahi to F...    1\n",
       "2357  \"BARKHA se bacha lu tujhe seene se laga lu, aa...    0\n",
       "2358  \"Bol raha hai mere saath debate karega.. Muh k...    0\n",
       "2359  Pakistan ko har world cup ke baad captain bada...    0\n",
       "\n",
       "[2360 rows x 2 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_humor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "\n",
    "# Fit and transform the text data\n",
    "X_train_humor = vectorizer.fit_transform(train_humor[\"Sentence\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SVM Linear Classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training svm_linear model...\n",
      "[LibSVM]Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize with SVM (linear)\n",
    "classifier = TextClassifier(model_type=\"svm_linear\")\n",
    "\n",
    "# Train on dataset\n",
    "classifier.fit(X_train_humor, train_humor['Tag'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test_humor = vectorizer.transform(val_humor[\"Sentence\"])\n",
    "\n",
    "y_test_humor = val_humor['Tag']\n",
    "\n",
    "# Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Model: svm_linear\n",
      "âœ… Accuracy: 0.7051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.65       119\n",
      "           1       0.77      0.73      0.75       176\n",
      "\n",
      "    accuracy                           0.71       295\n",
      "   macro avg       0.70      0.70      0.70       295\n",
      "weighted avg       0.71      0.71      0.71       295\n",
      "\n",
      "[[ 80  39]\n",
      " [ 48 128]]\n"
     ]
    }
   ],
   "source": [
    "classifier.evaluate(X_test_humor, y_test_humor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SVM RBF Classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training svm_rbf model...\n",
      "[LibSVM]Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize with SVM (linear)\n",
    "classifier = TextClassifier(model_type=\"svm_rbf\")\n",
    "\n",
    "# Train on dataset\n",
    "classifier.fit(X_train_humor, train_humor['Tag'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Model: svm_rbf\n",
      "âœ… Accuracy: 0.4949\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.92      0.60       119\n",
      "           1       0.80      0.20      0.33       176\n",
      "\n",
      "    accuracy                           0.49       295\n",
      "   macro avg       0.62      0.56      0.46       295\n",
      "weighted avg       0.65      0.49      0.43       295\n",
      "\n",
      "[[110   9]\n",
      " [140  36]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test_humor = vectorizer.transform(val_humor[\"Sentence\"])\n",
    "\n",
    "y_test_humor = val_humor['Tag']\n",
    "classifier.evaluate(X_test_humor, y_test_humor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Naive Bayes Classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training naive_bayes model...\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize with SVM (linear)\n",
    "classifier = TextClassifier(model_type=\"naive_bayes\")\n",
    "\n",
    "# Train on dataset\n",
    "classifier.fit(X_train_humor, train_humor['Tag'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Model: naive_bayes\n",
      "âœ… Accuracy: 0.6542\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.24      0.36       119\n",
      "           1       0.65      0.93      0.76       176\n",
      "\n",
      "    accuracy                           0.65       295\n",
      "   macro avg       0.68      0.59      0.56       295\n",
      "weighted avg       0.67      0.65      0.60       295\n",
      "\n",
      "[[ 29  90]\n",
      " [ 12 164]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test_humor = vectorizer.transform(val_humor[\"Sentence\"])\n",
    "\n",
    "y_test_humor = val_humor['Tag']\n",
    "classifier.evaluate(X_test_humor, y_test_humor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Logistic Regression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training logistic_regression model...\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize with SVM (linear)\n",
    "classifier = TextClassifier(model_type=\"logistic_regression\")\n",
    "\n",
    "# Train on dataset\n",
    "classifier.fit(X_train_humor, train_humor['Tag'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Model: logistic_regression\n",
      "âœ… Accuracy: 0.6847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.63      0.62       119\n",
      "           1       0.74      0.72      0.73       176\n",
      "\n",
      "    accuracy                           0.68       295\n",
      "   macro avg       0.67      0.68      0.67       295\n",
      "weighted avg       0.69      0.68      0.69       295\n",
      "\n",
      "[[ 75  44]\n",
      " [ 49 127]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test_humor = vectorizer.transform(val_humor[\"Sentence\"])\n",
    "\n",
    "y_test_humor = val_humor['Tag']\n",
    "classifier.evaluate(X_test_humor, y_test_humor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Random Forest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training random_forest model...\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize with SVM (linear)\n",
    "classifier = TextClassifier(model_type=\"random_forest\")\n",
    "\n",
    "# Train on dataset\n",
    "classifier.fit(X_train_humor, train_humor['Tag'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Model: random_forest\n",
      "âœ… Accuracy: 0.6475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.69      0.61       119\n",
      "           1       0.75      0.62      0.68       176\n",
      "\n",
      "    accuracy                           0.65       295\n",
      "   macro avg       0.65      0.65      0.64       295\n",
      "weighted avg       0.67      0.65      0.65       295\n",
      "\n",
      "[[ 82  37]\n",
      " [ 67 109]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test_humor = vectorizer.transform(val_humor[\"Sentence\"])\n",
    "\n",
    "y_test_humor = val_humor['Tag']\n",
    "classifier.evaluate(X_test_humor, y_test_humor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_humor = pd.read_csv('data/humor/train.csv')\n",
    "val_humor = pd.read_csv('data/humor/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jyotiraditya Scindia is like \"Rassi jal gayee ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ishant Sharma ko bahut late utaara.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.@twinitisha neeche plug nikla hua hai..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaj agar India final me hota to kam se kam New...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 stages of life of Mechanical Engineer:\\n\\n1)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>Nitish &amp; Lalu scared of Modi so much that agar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>.@ShirishKunder Sabzi bana ke rakhna nahi to F...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>\"BARKHA se bacha lu tujhe seene se laga lu, aa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>\"Bol raha hai mere saath debate karega.. Muh k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>Pakistan ko har world cup ke baad captain bada...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2360 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Tag\n",
       "0     Jyotiraditya Scindia is like \"Rassi jal gayee ...    1\n",
       "1                   Ishant Sharma ko bahut late utaara.    1\n",
       "2              .@twinitisha neeche plug nikla hua hai..    0\n",
       "3     Aaj agar India final me hota to kam se kam New...    0\n",
       "4     3 stages of life of Mechanical Engineer:\\n\\n1)...    1\n",
       "...                                                 ...  ...\n",
       "2355  Nitish & Lalu scared of Modi so much that agar...    1\n",
       "2356  .@ShirishKunder Sabzi bana ke rakhna nahi to F...    1\n",
       "2357  \"BARKHA se bacha lu tujhe seene se laga lu, aa...    0\n",
       "2358  \"Bol raha hai mere saath debate karega.. Muh k...    0\n",
       "2359  Pakistan ko har world cup ke baad captain bada...    0\n",
       "\n",
       "[2360 rows x 2 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_humor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "\n",
    "# Fit and transform the text data\n",
    "X_train_humor = vectorizer.fit_transform(train_humor[\"Sentence\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Preprocessing words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Removing words that start with numbers (e.g., usernames like \"123abc\")\n",
    "    text = re.sub(r\"\\b\\d+\\w*\", \"\", text)\n",
    "    \n",
    "    # Replace dots with space\n",
    "    text = text.replace(\".\", \" \")\n",
    "    \n",
    "    # Remove punctuation and special characters (keeping only alphabets and spaces)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    \n",
    "    # Tokenization (Splitting into words)\n",
    "    words = text.split()\n",
    "\n",
    "    # Reconstruct text\n",
    "    text = \" \".join(words)\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runinng the model with preprocessed text\n",
    "X_train = train_humor['Sentence'].apply(preprocess_text)\n",
    "X_val = val_humor['Sentence'].apply(preprocess_text)\n",
    "\n",
    "# train_hate['Sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "# Fit and transform the text data\n",
    "X_train = vectorizer.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training svm_linear model...\n",
      "[LibSVM]Training completed.\n"
     ]
    }
   ],
   "source": [
    "classifier = TextClassifier(model_type=\"svm_linear\")\n",
    "\n",
    "# Train on dataset\n",
    "classifier.fit(X_train, train_humor['Tag'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = vectorizer.transform(val_humor[\"Sentence\"])\n",
    "\n",
    "y_test = val_humor['Tag']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Model: svm_linear\n",
      "âœ… Accuracy: 0.7186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.70      0.67       119\n",
      "           1       0.78      0.73      0.76       176\n",
      "\n",
      "    accuracy                           0.72       295\n",
      "   macro avg       0.71      0.72      0.71       295\n",
      "weighted avg       0.72      0.72      0.72       295\n",
      "\n",
      "[[ 83  36]\n",
      " [ 47 129]]\n"
     ]
    }
   ],
   "source": [
    "classifier.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Sarcasm Classification`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sarcasm = pd.read_csv('data/sarcasm/train.csv')\n",
    "val_sarcasm = pd.read_csv('data/sarcasm/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of words</th>\n",
       "      <th>Training Set</th>\n",
       "      <th>Validation Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sarcasm Words</td>\n",
       "      <td>403</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Sarcasm Words</td>\n",
       "      <td>3797</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Number of words  Training Set  Validation Set\n",
       "0      Sarcasm Words           403              51\n",
       "1  Not Sarcasm Words          3797             474"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasmCount_train = len(train_sarcasm[train_sarcasm['Tag'] == 1])\n",
    "notsarcasmCount_train = len(train_sarcasm[train_sarcasm['Tag'] == 0])\n",
    "sarcasmCount_val = len(val_sarcasm[val_sarcasm['Tag'] == 1])\n",
    "notsarcasmCount_val = len(val_sarcasm[val_sarcasm['Tag'] == 0])\n",
    "\n",
    "word_count_df = pd.DataFrame(\n",
    "         {\n",
    "        'Number of words': [\"Sarcasm Words\", \"Not Sarcasm Words\"],\n",
    "        'Training Set': [sarcasmCount_train, notsarcasmCount_train],\n",
    "        'Validation Set': [sarcasmCount_val, notsarcasmCount_val]\n",
    "        },\n",
    "    )\n",
    "word_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SVM Linear Classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "\n",
    "# Fit and transform the text data\n",
    "X_train_sarcasm = vectorizer.fit_transform(train_sarcasm[\"Sentence\"])\n",
    "# Convert sparse matrix to array for better readability\n",
    "# X_array = X.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training svm_linear model...\n",
      "[LibSVM]Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize with SVM (linear)\n",
    "classifier = TextClassifier(model_type=\"svm_linear\")\n",
    "\n",
    "# Train on dataset\n",
    "classifier.fit(X_train_sarcasm, train_sarcasm['Tag'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test_sarcasm = vectorizer.transform(val_sarcasm[\"Sentence\"])\n",
    "\n",
    "y_test_sarcasm = val_sarcasm['Tag']\n",
    "\n",
    "# Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Model: svm_linear\n",
      "âœ… Accuracy: 0.9676\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       474\n",
      "           1       0.90      0.75      0.82        51\n",
      "\n",
      "    accuracy                           0.97       525\n",
      "   macro avg       0.94      0.87      0.90       525\n",
      "weighted avg       0.97      0.97      0.97       525\n",
      "\n",
      "[[470   4]\n",
      " [ 13  38]]\n"
     ]
    }
   ],
   "source": [
    "classifier.evaluate(X_test_sarcasm, y_test_sarcasm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SVM RBF Classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training svm_rbf model...\n",
      "[LibSVM]Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize with SVM (linear)\n",
    "classifier = TextClassifier(model_type=\"svm_rbf\")\n",
    "\n",
    "# Train on dataset\n",
    "classifier.fit(X_train_sarcasm, train_sarcasm['Tag'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Model: svm_rbf\n",
      "âœ… Accuracy: 0.9562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       474\n",
      "           1       0.83      0.69      0.75        51\n",
      "\n",
      "    accuracy                           0.96       525\n",
      "   macro avg       0.90      0.84      0.86       525\n",
      "weighted avg       0.95      0.96      0.95       525\n",
      "\n",
      "[[467   7]\n",
      " [ 16  35]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test_sarcasm = vectorizer.transform(val_sarcasm[\"Sentence\"])\n",
    "\n",
    "y_test_sarcasm = val_sarcasm['Tag']\n",
    "classifier.evaluate(X_test_sarcasm, y_test_sarcasm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Naive Bayes Classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training naive_bayes model...\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize with SVM (linear)\n",
    "classifier = TextClassifier(model_type=\"naive_bayes\")\n",
    "\n",
    "# Train on dataset\n",
    "classifier.fit(X_train_sarcasm, train_sarcasm['Tag'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Model: naive_bayes\n",
      "âœ… Accuracy: 0.9048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95       474\n",
      "           1       1.00      0.02      0.04        51\n",
      "\n",
      "    accuracy                           0.90       525\n",
      "   macro avg       0.95      0.51      0.49       525\n",
      "weighted avg       0.91      0.90      0.86       525\n",
      "\n",
      "[[474   0]\n",
      " [ 50   1]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test_sarcasm = vectorizer.transform(val_sarcasm[\"Sentence\"])\n",
    "\n",
    "y_test_sarcasm = val_sarcasm['Tag']\n",
    "classifier.evaluate(X_test_sarcasm, y_test_sarcasm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Logistic Regression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training logistic_regression model...\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize with SVM (linear)\n",
    "classifier = TextClassifier(model_type=\"logistic_regression\")\n",
    "\n",
    "# Train on dataset\n",
    "classifier.fit(X_train_sarcasm, train_sarcasm['Tag'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Model: logistic_regression\n",
      "âœ… Accuracy: 0.9619\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       474\n",
      "           1       0.76      0.88      0.82        51\n",
      "\n",
      "    accuracy                           0.96       525\n",
      "   macro avg       0.87      0.93      0.90       525\n",
      "weighted avg       0.97      0.96      0.96       525\n",
      "\n",
      "[[460  14]\n",
      " [  6  45]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test_sarcasm = vectorizer.transform(val_sarcasm[\"Sentence\"])\n",
    "\n",
    "y_test_sarcasm = val_sarcasm['Tag']\n",
    "classifier.evaluate(X_test_sarcasm, y_test_sarcasm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Random Forest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training random_forest model...\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize with SVM (linear)\n",
    "classifier = TextClassifier(model_type=\"random_forest\")\n",
    "\n",
    "# Train on dataset\n",
    "classifier.fit(X_train_sarcasm, train_sarcasm['Tag'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Model: random_forest\n",
      "âœ… Accuracy: 0.9067\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95       474\n",
      "           1       1.00      0.04      0.08        51\n",
      "\n",
      "    accuracy                           0.91       525\n",
      "   macro avg       0.95      0.52      0.51       525\n",
      "weighted avg       0.92      0.91      0.87       525\n",
      "\n",
      "[[474   0]\n",
      " [ 49   2]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test_sarcasm = vectorizer.transform(val_sarcasm[\"Sentence\"])\n",
    "\n",
    "y_test_sarcasm = val_sarcasm['Tag']\n",
    "classifier.evaluate(X_test_sarcasm, y_test_sarcasm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Preprocessing words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Removing usernames (@mentions can be useful for context, so it's optional)\n",
    "    text = re.sub(r\"@[A-Za-z0-9]+\", \"\", text)\n",
    "    \n",
    "    # Removing words that start with numbers (e.g., usernames like \"123abc\")\n",
    "    text = re.sub(r\"\\b\\d+\\w*\", \"\", text)\n",
    "    \n",
    "    # Replace dots with space\n",
    "    text = text.replace(\".\", \" \")\n",
    "    \n",
    "    # Remove punctuation and special characters (keeping only alphabets and spaces)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    \n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runinng the model with preprocessed text\n",
    "X_train = train_sarcasm['Sentence'].apply(preprocess_text)\n",
    "X_val = val_sarcasm['Sentence'].apply(preprocess_text)\n",
    "\n",
    "# train_hate['Sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "# Fit and transform the text data\n",
    "X_train = vectorizer.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training svm_linear model...\n",
      "[LibSVM]Training completed.\n"
     ]
    }
   ],
   "source": [
    "classifier = TextClassifier(model_type=\"svm_linear\")\n",
    "\n",
    "# Train on dataset\n",
    "classifier.fit(X_train, train_sarcasm['Tag'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = vectorizer.transform(val_sarcasm[\"Sentence\"])\n",
    "\n",
    "y_test = val_sarcasm['Tag']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Model: svm_linear\n",
      "âœ… Accuracy: 0.9657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       474\n",
      "           1       0.92      0.71      0.80        51\n",
      "\n",
      "    accuracy                           0.97       525\n",
      "   macro avg       0.95      0.85      0.89       525\n",
      "weighted avg       0.96      0.97      0.96       525\n",
      "\n",
      "[[471   3]\n",
      " [ 15  36]]\n"
     ]
    }
   ],
   "source": [
    "classifier.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MYENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
